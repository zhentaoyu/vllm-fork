# Source: chatqna-charts/templates/configmap.yaml
# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0

apiVersion: v1
kind: ConfigMap
metadata:
  name: chatqna-config
  namespace: default
data:
  EMBEDDING_MODEL_ID: BAAI/bge-base-en-v1.5
  EMBEDDING_SERVER_HOST_IP: embedding-dependency-svc
  HUGGINGFACEHUB_API_TOKEN: ${HF_TOKEN}
  INDEX_NAME: rag-redis
    #LLM_MODEL: Intel/neural-chat-7b-v3-3
  #LLM_MODEL_ID: meta-llama/Meta-Llama-3-8B
  #LLM_MODEL:
  LLM_MODEL_ID: meta-llama/Meta-Llama-3.1-8B-Instruct
  LLM_MODEL: meta-llama/Meta-Llama-3.1-8B-Instruct
  LLM_SERVER_HOST_IP: llm-dependency-svc
  NODE_SELECTOR: opea
  REDIS_URL: redis://vector-db.default.svc.cluster.local:6379
  RERANK_MODEL_ID: BAAI/bge-reranker-base
  RERANK_SERVER_HOST_IP: reranking-dependency-svc
  RETRIEVER_SERVICE_HOST_IP: retriever-svc
  TEI_EMBEDDING_ENDPOINT: http://embedding-dependency-svc.default.svc.cluster.local:6006
  TEI_ENDPOINT: http://embedding-dependency-svc.default.svc.cluster.local:6006
  TEI_RERANKING_ENDPOINT: http://reranking-dependency-svc.default.svc.cluster.local:8808
  TGI_LLM_ENDPOINT: http://llm-dependency-svc.default.svc.cluster.local:9009

  VLLM_SKIP_WARMUP: "true"
  LLM_KV_TRANSFER_DRIVER: "disk_kv_transfer"
  LLM_SERVER_PORT: '9009'
  RERANK_SERVER_PORT: '8808'
  EMBEDDING_SERVER_PORT: '6006'

---
# Source: chatqna-charts/templates/service.yaml
# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0
apiVersion: v1
kind: Service
metadata:
  name: chatqna-backend-server-svc
  namespace: default
spec:
  ports:
    - name: service
      nodePort: 30888
      port: 8888
      targetPort: 8888
  selector:
    app: chatqna-backend-server-deploy
  type: NodePort
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: dataprep-svc
  namespace: default
spec:
  ports:
    - name: port1
      port: 6007
      targetPort: 6007
  selector:
    app: dataprep-deploy
  type: ClusterIP
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: embedding-dependency-svc
  namespace: default
spec:
  ports:
    - name: service
      port: 6006
      targetPort: 80
  selector:
    app: embedding-dependency-deploy
  type: ClusterIP
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: llm-dependency-svc
  namespace: default
spec:
  ports:
    - name: service
      port: 9009
      targetPort: 8000
  selector:
    app: llm-dependency-deploy
  type: ClusterIP
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: reranking-dependency-svc
  namespace: default
spec:
  ports:
    - name: service
      port: 8808
      targetPort: 80
  selector:
    app: reranking-dependency-deploy
  type: ClusterIP
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: retriever-svc
  namespace: default
spec:
  ports:
    - name: service
      port: 7000
      targetPort: 7000
  selector:
    app: retriever-deploy
  type: ClusterIP
---
# Source: chatqna-charts/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: vector-db
  namespace: default
spec:
  ports:
    - name: vector-db-service
      port: 6379
      targetPort: 6379
    - name: vector-db-insight
      port: 8001
      targetPort: 8001
  selector:
    app: vector-db
  type: ClusterIP
---
# Source: chatqna-charts/templates/deployment.yaml
# Copyright (C) 2024 Intel Corporation
# SPDX-License-Identifier: Apache-2.0
apiVersion: apps/v1
kind: Deployment
metadata:
  name: chatqna-backend-server-deploy
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: chatqna-backend-server-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: chatqna-backend-server-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        image: opea/chatqna:latest

        imagePullPolicy: IfNotPresent
        name: chatqna-backend-server-deploy
        ports:
          - containerPort: 8888

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: chatqna-backend-server-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: dataprep-deploy
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: dataprep-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: dataprep-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        image: opea/dataprep-redis:latest

        imagePullPolicy: IfNotPresent
        name: dataprep-deploy
        ports:
          - containerPort: 6007

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: dataprep-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vector-db
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: vector-db
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: vector-db
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        image: redis/redis-stack:7.2.0-v9

        imagePullPolicy: IfNotPresent
        name: vector-db
        ports:
          - containerPort: 6379
          - containerPort: 8001

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: vector-db
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: retriever-deploy
  namespace: default
spec:
  replicas: 2

  selector:
    matchLabels:
      app: retriever-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: retriever-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        image: opea/retriever-redis:latest

        imagePullPolicy: IfNotPresent
        name: retriever-deploy
        ports:
          - containerPort: 7000

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: retriever-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: embedding-dependency-deploy
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: embedding-dependency-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: embedding-dependency-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        args:
          - --model-id
          - "$(EMBEDDING_MODEL_ID)"
          - --auto-truncate
        image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5

        imagePullPolicy: IfNotPresent
        name: embedding-dependency-deploy
        ports:
          - containerPort: 80
        volumeMounts:
          - mountPath: /data
            name: model-volume
          - mountPath: /dev/shm
            name: shm

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: embedding-dependency-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
        - name: model-volume
          hostPath:
            path: /mnt/models
            type: Directory
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reranking-dependency-deploy
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: reranking-dependency-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: reranking-dependency-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        args:
          - --model-id
          - "$(RERANK_MODEL_ID)"
          - --auto-truncate
        env:
          - name: OMPI_MCA_btl_vader_single_copy_mechanism
            value: "none"
          - name: PT_HPU_ENABLE_LAZY_COLLECTIVES
            value: "true"
          - name: runtime
            value: "habana"
          - name: HABANA_VISIBLE_DEVICES
            value: "all"
          - name: MAX_WARMUP_SEQUENCE_LENGTH
            value: "512"
        image: opea/tei-gaudi:latest

        imagePullPolicy: IfNotPresent
        name: reranking-dependency-deploy
        resources:
          limits:
            habana.ai/gaudi: 1
        volumeMounts:
          - mountPath: /data
            name: model-volume
          - mountPath: /dev/shm
            name: shm

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: reranking-dependency-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
        - name: model-volume
          hostPath:
            path: /mnt/models
            type: Directory
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
---
# Source: chatqna-charts/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-dependency-deploy
  namespace: default
spec:
  replicas: 1

  selector:
    matchLabels:
      app: llm-dependency-deploy
  template:
    metadata:
      annotations:
        sidecar.istio.io/rewriteAppHTTPProbers: 'true'
      labels:
        app: llm-dependency-deploy
    spec:
      containers:
      - envFrom:
        - configMapRef:
            name: chatqna-config
        command: ["/bin/bash", "-c"]
        args: ["tail -f /dev/null"]
        #args: ["python3 -m vllm.entrypoints.openai.api_server --model $LLM_MODEL_ID --tensor-parallel-size 1 --host 0.0.0.0 --port 80 --block-size 128 --max-num-seqs 256 --max-seq_len-to-capture 2048"]
        env:
          - name: OMPI_MCA_btl_vader_single_copy_mechanism
            value: "none"
          - name: PT_HPU_ENABLE_LAZY_COLLECTIVES
            value: "true"
          - name: runtime
            value: "habana"
          - name: HABANA_VISIBLE_DEVICES
            value: "all"
        image: vllm-hpukv-no-command:latest
        #image: vllm-hpukv:latest

        imagePullPolicy: IfNotPresent
        name: llm-dependency-deploy
        ports:
          - containerPort: 8000
        resources:
          limits:
            habana.ai/gaudi: 2
        volumeMounts:
          - mountPath: /data
            name: model-volume
          - mountPath: /dev/shm
            name: shm

      hostIPC: true
      nodeSelector:
        node-type: opea
      serviceAccountName: default
      topologySpreadConstraints:
      - labelSelector:
          matchLabels:
            app: llm-dependency-deploy
        maxSkew: 1
        topologyKey: kubernetes.io/hostname
        whenUnsatisfiable: ScheduleAnyway
      volumes:
        - name: model-volume
          hostPath:
            path: /mnt/models
            type: Directory
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi